{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#ImportError: You need to install sacremoses to use BioGptTokenizer. See https://pypi.org/project/sacremoses/ for installation.\n",
    "#!pip install sacremoses\n",
    "#!pip install torch\n",
    "#!pip install pandas\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mmfs1/home/6672islamk/venv37/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-08 20:36:42.561715: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-08 20:36:44.258357: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64\n",
      "2023-05-08 20:36:44.258513: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64:/cm/local/apps/gcc/9.2.0/lib:/cm/local/apps/gcc/9.2.0/lib64\n",
      "2023-05-08 20:36:44.258523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BioGptForCausalLM, BioGptTokenizer, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset \n",
    "import datetime\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'./Data/train_small.csv')\n",
    "data = pd.read_csv(r'./Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Chief Complaint'] = data['Chief Complaint'].apply(lambda x: x.replace(u'\\xa0',u' '))\n",
    "data['Chief Complaint'] = data['Chief Complaint'].apply(lambda x: x.replace('\\u200a',' '))\n",
    "\n",
    "all_sentences = data['Chief Complaint'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size :  7593\n",
      "samples     : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Patient reportedly cut her LLE while putting on a compression sock, patient was intially hypotensive and c/o generalized weakness, bleeding controlled pta.',\n",
       " 'fall from standing at home. left jaw abrasion, left shoulder pain.',\n",
       " '\"The blood pressure medicine they gave me makes me throw up\", pmhx:  HTN. bipolar',\n",
       " 'hearing voices, depression, pt. states \"the devil is trying to get me\". hyperreligious/talking to self during triage assessment.',\n",
       " 'Throat ache, hemoptysis, blood in urine, PMH NAFLD',\n",
       " 'pain in groin, scrotum and lower back, swelling in scrotum x 2 days. burning w/ urination. pmh: sleep apnea',\n",
       " 'R sided HA starting \"a few minutes ago\". Denies blurry vision or dizziness, also denies trauma. Hx: HIV',\n",
       " 'c/o  bright red bloody bowel movement at 0405. c/o r sided abd cramping assoc with it. denies pmh',\n",
       " 'swallowed a sip of hydrogen peroxide about 2041. family reports he was crying and \"turning red\". now alert & calm',\n",
       " 'flu symptoms chills, low grade fevers, nausea/vomiting. wrestling injry to left arm.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"sample size : \",len(all_sentences))\n",
    "print(\"samples     : \" )\n",
    "all_sentences[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BioGptForCausalLM.from_pretrained(\"microsoft/biogpt\")\n",
    "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2448]\n",
      "[2, 3332]\n",
      "[2, 4609]\n",
      "[2, 6854, 32693, 4725]\n",
      "[2, 1349, 26, 702]\n"
     ]
    }
   ],
   "source": [
    "#tokenizer some samples\n",
    "print( tokenizer.encode(\"ED\") )\n",
    "print( tokenizer.encode(\"AM\") )\n",
    "print( tokenizer.encode(\"swelling\") )\n",
    "print( tokenizer.encode(\"twisting ankle\") )\n",
    "print( tokenizer.encode(\"upper/right\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len 86\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(tokenizer.encode(s)) for s in all_sentences])\n",
    "\n",
    "print(f\"max_len {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mark beginning and end of sentences with with sos and eos\n",
    "def tokenize_seq(sent,tokenizer,max_length):\n",
    "  return tokenizer('<sos>'+ sent + '<eos>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "\n",
    "class CCDataset(Dataset):\n",
    "\n",
    "  def __init__(self, sentences, tokenizer, gpt_type=\"bio-gpt\", max_length=max_len):\n",
    "\n",
    "    self.tokenizer = tokenizer \n",
    "    self.input_ids = []\n",
    "    self.attn_masks = []\n",
    "\n",
    "    for sentence in sentences:      \n",
    "      encodings = tokenize_seq(sentence,tokenizer,max_length)\n",
    "            \n",
    "      self.input_ids.append(torch.tensor(encodings['input_ids']))\n",
    "      self.attn_masks.append(torch.tensor(encodings['attention_mask']))\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.input_ids[idx], self.attn_masks[idx]   \n",
    "\n",
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size : 6833\n",
      "val_size   : 760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an instance of Dataset\n",
    "dataset = CCDataset(all_sentences, tokenizer, max_length=max_len)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "print(\"train_size :\",train_size)\n",
    "print(\"val_size   :\",val_size)\n",
    "\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    2,   109,  4514,   279,   361,  2974, 24902,  3427,  3109,  7219,\n",
       "           316,   247, 32580,    25,    14,  3341,   578, 12704,     7,   125,\n",
       "            17,   501, 24857, 13709,     8,   457,    26,   399,  3891,  7052,\n",
       "             7,  1720,   691,   341,  4011,     4,   109,   768,  2842,   361,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set,  sampler = RandomSampler(train_set), batch_size = 32)\n",
    "validation_dataloader = DataLoader(val_set, sampler = SequentialSampler(val_set), batch_size = 32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device not found\n",
      "No GPU available, using the CPU instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 20:37:43.966081: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-08 20:37:44.094458: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-05-08 20:37:44.094507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (raj-ln1): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    print('GPU device not found')\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('Use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0005)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at every step i want to check if generations are getting better.\n",
    "def eval_keywords(model, keywords):\n",
    "  model.eval()\n",
    "  for keyword in keywords:\n",
    "    input_seq = \"<sos> \" + keyword\n",
    "    generated = torch.tensor(tokenizer.encode(input_seq)).unsqueeze(0)\n",
    "    generated = generated.to(device)\n",
    "    sample_outputs = model.generate(\n",
    "                                generated, \n",
    "                                do_sample=True,   \n",
    "                                top_k=30, \n",
    "                                max_length = 100,\n",
    "                                top_p=0.90, \n",
    "                                num_return_sequences=2\n",
    "                                )\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "      print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "\n",
    "#keywords = [\"swollen tonsils, LMP 10/19/98 have\",\"complaints of blood in\",\"swollen tonsils, LMP 10/19/98 have not\",\"complaints of blood in stool within the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at every step i want to check if generations are getting better.\n",
    "def eval_keywords(keywords):\n",
    "  model.eval()\n",
    "  for keyword in keywords:\n",
    "    input_seq = \"<sos> \" + keyword\n",
    "    generated = torch.tensor(tokenizer.encode(input_seq)).unsqueeze(0)\n",
    "    generated = generated.to(device)\n",
    "    sample_outputs = model.generate(\n",
    "                                generated, \n",
    "                                do_sample=True,   \n",
    "                                top_k=30, \n",
    "                                max_length = 100,\n",
    "                                top_p=0.90, \n",
    "                                num_return_sequences=2\n",
    "                                )\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "      print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "\n",
    "keywords = [\"swollen tonsils, LMP 10/19/98 have\",\"complaints of blood in\",\"swollen tonsils, LMP 10/19/98 have not\",\"complaints of blood in stool within the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call model with a batch of input\n",
    "def process_one_batch(batch):\n",
    "  b_input_ids = batch[0].to(device)\n",
    "  b_labels = batch[0].to(device)\n",
    "  b_masks = batch[1].to(device)\n",
    "  outputs  = model(b_input_ids,  attention_mask = b_masks,labels=b_labels)\n",
    "  return outputs, b_input_ids\n",
    "\n",
    "#do one epoch for training\n",
    "def train_epoch():\n",
    "  t0 = time.time()\n",
    "  total_train_loss = 0\n",
    "  model.train()\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        model.zero_grad()        \n",
    "        outputs, input_ids = process_one_batch( batch)\n",
    "        loss = outputs[0]  \n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "  avg_train_loss = total_train_loss / len(train_dataloader)  \n",
    "  print(\"avg_train_loss\",avg_train_loss)  \n",
    "  elapsed_time = format_time(time.time() - t0)\n",
    "  print(\"elapsed time for 1 training epoch : \",elapsed_time)\n",
    "\n",
    "#do one epoch for eval\n",
    "def eval_epoch():\n",
    "  t0 = time.time()\n",
    "  total_eval_loss = 0\n",
    "  nb_eval_steps = 0\n",
    "  # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:            \n",
    "        \n",
    "    with torch.no_grad():        \n",
    "      outputs, input_ids = process_one_batch( batch)\n",
    "      loss = outputs[0]              \n",
    "      batch_loss = loss.item()\n",
    "      total_eval_loss += batch_loss\n",
    "      logits = outputs.logits\n",
    "\n",
    "  # Compute the perplexity\n",
    "  log_probs = torch.nn.functional.log_softmax(logits[0, :-1], dim=-1)\n",
    "  target = input_ids[0, 1:]\n",
    "  perplexity = torch.exp(-log_probs.gather(dim=-1, index=target.unsqueeze(-1)).sum() / target.size(0))\n",
    "  print(\"Perplexity:\", perplexity.item())\n",
    "\n",
    "  avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "  print(\"avg_val_loss\",avg_val_loss) \n",
    "  elapsed_time = format_time(time.time() - t0)\n",
    "  print(\"elapsed time for 1 eval epoch : \",elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './Trained_models/bioGPT_small/'\n",
    "model_path = './Trained_models/bioGPT_large/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For small dataset\n",
    "\n",
    "avg_train_loss 4.880961608886719\n",
    "\n",
    "elapsed time for 1 training epoch :  0:04:02\n",
    "\n",
    "Perplexity: 13.712059020996094\n",
    "\n",
    "avg_val_loss 2.2061687111854553\n",
    "\n",
    "elapsed time for 1 eval epoch :  0:00:14\n",
    "\n",
    "avg_train_loss 1.8096208175023396\n",
    "\n",
    "elapsed time for 1 training epoch :  0:03:25\n",
    "\n",
    "Perplexity: 9.81473445892334\n",
    "\n",
    "avg_val_loss 1.8228430151939392\n",
    "\n",
    "elapsed time for 1 eval epoch :  0:00:12\n",
    "\n",
    "# For Large dataset\n",
    "\n",
    "avg_train_loss 1.585690320652222\n",
    "\n",
    "elapsed time for 1 training epoch :  0:49:10\n",
    "\n",
    "Perplexity: 5.314290523529053\n",
    "\n",
    "avg_val_loss 1.2847954332828522\n",
    "\n",
    "elapsed time for 1 eval epoch :  0:03:17\n",
    "\n",
    "avg_train_loss 1.049023493706623\n",
    "\n",
    "elapsed time for 1 training epoch :  0:48:53\n",
    "\n",
    "Perplexity: 5.240231990814209\n",
    "\n",
    "avg_val_loss 1.2551174809535344\n",
    "\n",
    "elapsed time for 1 eval epoch :  0:03:04\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 1.585690320652222\n",
      "elapsed time for 1 training epoch :  0:49:10\n",
      "Perplexity: 5.314290523529053\n",
      "avg_val_loss 1.2847954332828522\n",
      "elapsed time for 1 eval epoch :  0:03:17\n",
      "avg_train_loss 1.049023493706623\n",
      "elapsed time for 1 training epoch :  0:48:53\n",
      "Perplexity: 5.240231990814209\n",
      "avg_val_loss 1.2551174809535344\n",
      "elapsed time for 1 eval epoch :  0:03:04\n"
     ]
    }
   ],
   "source": [
    "train_epoch()\n",
    "eval_epoch()\n",
    "train_epoch()\n",
    "eval_epoch()\n",
    "model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"swollen tonsils, LMP 10/19/98 have\",\"complaints of blood in\",\"swollen tonsils, LMP 10/19/98 have not\",\"complaints of blood in stool within the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: < sos > swollen tonsils, LMP 10 / 19 / 98 have been seen at MMC. given levaquin at home and given levaquin for flu. not improving. < eos >\n",
      "1: < sos > swollen tonsils, LMP 10 / 19 / 98 have been seen x 2 days for same; hx adhd, seizures < eos >\n",
      "0: < sos > complaints of blood in urine, urination x 1 week; PMH: Hep-C, Hep-C < eos >\n",
      "1: < sos > complaints of blood in urine, lower back pain, chest pain, low back pain x 4 days; PMH: HTN < eos >\n",
      "0: < sos > swollen tonsils, LMP 10 / 19 / 98 have not been feeling better. PMH: HTN < eos >\n",
      "1: < sos > swollen tonsils, LMP 10 / 19 / 98 have not felt \"something\" per mom \"< eos >\n",
      "0: < sos > complaints of blood in stool within the stool; \"I've had my pancreas removed this AM. I just had my pancreas removed & it did so, I had my pancreas removed.\" denies any complaints; < eos >\n",
      "1: < sos > complaints of blood in stool within the stool last night, N / V and D x1 day. PMH: COPD, HTN, DM, HLD < eos >\n"
     ]
    }
   ],
   "source": [
    "model = BioGptForCausalLM.from_pretrained(model_path)\n",
    "eval_keywords( model, keywords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 2.2862285653750103\n",
      "elapsed time for 1 training epoch :  0:05:15\n",
      "avg_val_loss 2.288579225540161\n",
      "elapsed time for 1 eval epoch :  0:00:14\n",
      "0: < sos > swollen tonsils, LMP 10 / 19 / 98 have x/ HTN, / eos >\n",
      "1: < sos > swollen tonsils, LMP 10 / 19 / 98 have for PMPMx /.\n",
      "0: < sos > complaints of blood in > HTN / PMH, Hx / PMmmxx mx. PMPMH: eos >\n",
      "1: < sos > complaints of blood in PMH.\n",
      "0: < sos > swollen tonsils, LMP 10 / 19 / 98 have not ies.\n",
      "1: < sos > swollen tonsils, LMP 10 / 19 / 98 have not eos >\n",
      "0: < sos > complaints of blood in stool within the x. PMH to > eos >\n",
      "1: < sos > complaints of blood in stool within the eos >\n"
     ]
    }
   ],
   "source": [
    "train_epoch()\n",
    "eval_epoch()\n",
    "eval_keywords( keywords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.5711676220099131\n",
      "elapsed time for 1 training epoch :  0:03:30\n",
      "avg_val_loss 2.0633411407470703\n",
      "elapsed time for 1 eval epoch :  0:00:14\n",
      "0: < sos > swollen tonsils, LMP 10 / 19 / 98 have a mass in chest on same side pushing against spine < eos >. sent from PCP abnormal asymptomatic PMHx: negative for < eos >\n",
      "1: < sos > swollen tonsils, LMP 10 / 19 / 98 have gone through 4 weeks and 5 days < eos > erwith hn, left heart pain < eos >. States was placed on for being. hx ter ter in triage. last chemo in < eos >\n",
      "0: < sos > complaints of blood in urine since last night, pt states she was in withdrawals now. pt states she feels like she's in withdrawals now. PMHX: depression, anxiety < eos >, HTN < eos >\n",
      "1: < sos > complaints of blood in face, chest tightness x 1 week < eos > esting and not feeling like they heard \"in ess. Hx endocarditis in Son in Ancef in Car 26, 07. < eos >\n",
      "0: < sos > swollen tonsils, LMP 10 / 19 / 98 have not been having surgery due to LMP 1 year ago < eos >. Had not feeling like I've been getting in and unless they hurt to kill myself < eos >\n",
      "1: < sos > swollen tonsils, LMP 10 / 19 / 98 have not notified surgery on 11 / 18. < eos > ed hn, bilateral flank pain, worse last night. c / o back pain. + ex plan. fell down to R flank pain < eos >\n",
      "0: < sos > Yokohama pain to R leg since this morning < eos >. pmhx: htn, high cholest. < eos >\n",
      "1: < sos > Yokohama valley medical center, accepted by plastics MD Cunningham. Denies other injury. Med hx. < eos >, H< eos >, left heart attack. Hx. < eos\n",
      "0: < sos > complaints of blood in stool within the last night, no injury. Seen by pcp, told it would fall. < eos > ermom n < eos >\n",
      "1: < sos > complaints of blood in stool within the last night, weight loss < eos >. enlarged prostate in mid upper back & symptoms. hx: htn, htn, dm2, high cholest. < eos >\n"
     ]
    }
   ],
   "source": [
    "train_epoch()\n",
    "eval_epoch()\n",
    "eval_keywords( keywords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss 0.4855570097764333\n",
      "elapsed time for 1 training epoch :  0:03:30\n",
      "avg_val_loss 2.053557336330414\n",
      "elapsed time for 1 eval epoch :  0:00:14\n",
      "0: < sos > swollen tonsils, LMP 10 / 19 / 98 have gone through 4 pads- G1 LMG 10 / 27 and 2013. Denies other symptoms < eos >. pmh < eos >. < eos >\n",
      "1: < sos > swollen tonsils, LMP 10 / 19 / 98 have had abdominal surgery and couldn't void at home. PMH: cervical fusion, right ear drainage. pmh: asthma < eos >, right ear pain < eos >\n",
      "0: < sos > complaints of blood in urine since last night, states that her last night has had blood in urine since then. Hit is out of blood pressure medication; denies cough. Also c / o back pain in lower back, denies dysuria. < eos > SIS w / d, c / o intermittent pain in\n",
      "1: < sos > complaints of blood in lower back and fluid on L buttocks. Pt. pt states that she feels like her's going to the clinic and she states that she feels like she has gone through blood clots in lower back. pta. Pt denies blood clots. Pt denies blood or fluid. pmhx. Pt, ra, htn, ra, ra, and chills. < eos >\n",
      "0: < sos > swollen tonsils, LMP 10 / 19 / 98 have not had notified surgery \"< eos > SIS in being watering sat home, pmh: denies < eos >, htn < eos >\n",
      "1: < sos > swollen tonsils, LMP 10 / 19 / 98 have not had abdominal surgery because it was too infected to operate; PMH: denies < eos > SIS < eos > SIS < eos >, right flank pain < eos >\n",
      "0: < sos > Yokohama valley medical center, hospits stated she had decreased appetitie, now c / o being punched a wall twice, hit by a desk, a special needs child and adolescent, no back pain < eos >. denies intermittent pain in back h, htn, dm2, gout, htn,\n",
      "1: < sos > Yokohama, puncture wound to neck, chest and shoulder, bleeding and low back pain. < eos > se pain, fluid drawn out of blood in blood, chest pain < eos > SIS >, \"< eos >\n",
      "0: < sos > complaints of blood in stool within the last night, states blood in stool, nausea, constipation, and bilateral leg pain x 1 month. pmhx: miscarriage < eos > states LMP < eos > j< TI, PMH\n",
      "1: < sos > complaints of blood in stool within the last week. PMH: HTN, low back pain, depression, anxiety < eos > SIS > SIS > jx 3 episodes. pain, upper back pain. pain, dm2 < eos >. hx, dm2, high\n"
     ]
    }
   ],
   "source": [
    "train_epoch()\n",
    "eval_epoch()\n",
    "eval_keywords( keywords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keywords = [\"swollen tonsils, LMP 10/19/98 have\",\"complaints of blood in\",\"swollen tonsils, LMP 10/19/98 have not\",\"complaints of blood in stool within the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"Pelvic pain and vaginal bleeding X 1 wk. Soaking a pad about every 2 hours. Syncopal episode yesterday, denies\", \"left knee pain with movement for past 2 weeks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: < sos > Pelvic pain and vaginal bleeding X 1 wk. Soaking a pad about every 2 hours. Syncopal episode yesterday, denies hitting head, denies PMH, + ETOH < eos >\n",
      "1: < sos > Pelvic pain and vaginal bleeding X 1 wk. Soaking a pad about every 2 hours. Syncopal episode yesterday, denies nausea / vomitting, + LOC < eos >\n",
      "0: < sos > left knee pain with movement for past 2 weeks. PMH: DM, Hep C < eos >\n",
      "1: < sos > left knee pain with movement for past 2 weeks, also c / o knee pain x1 month. pmhx: chronic back pain, diabetes, HTN < eos >\n"
     ]
    }
   ],
   "source": [
    "model = BioGptForCausalLM.from_pretrained(model_path)\n",
    "eval_keywords( model, keywords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"Pelvic pain and vaginal bleeding\", \"left knee pain with movement for past 2 weeks\", \"severe abdominal pain for 3 days. recently admitted for h pylori, states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left thumb injury with needle nose pliers. Bleeding controlled\n",
    "# Returned for rabies\n",
    "# left knee pain with movement for past 2 weeks post workout routine, PMH- High Cholesterol\n",
    "# swelling and redness to left side of face, pt states that there was a\n",
    "# C/O back pain after falling backwards onto back from 6ft porch, denies LOC or any head or nack pain. States it is\n",
    "# States it is hard to catch his breath PMHX bipolar schizophrenia\n",
    "#  Has tried Imtrex and nasal\n",
    "# Headahce, fever, chills, bodyaches, non productive cough since this AM. PMH HTN\n",
    "keywords = [\"severe abdominal pain for\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: < sos > severe abdominal pain for the past few days, denies pmh < eos >\n",
      "1: < sos > severe abdominal pain for 2 weeks with nausea, vomiting and diarrhea x 3 days; hx chole < eos >\n"
     ]
    }
   ],
   "source": [
    "model = BioGptForCausalLM.from_pretrained(model_path)\n",
    "eval_keywords( model, keywords )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
